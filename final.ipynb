{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvYYNYEv_Oq-",
        "outputId": "ade778b0-a101-47c0-8fb9-8abcc0998331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['timestamp', 'src_ip', 'dst_ip', 'protocol', 'src_port', 'dst_port',\n",
            "       'length', 'attack_type'],\n",
            "      dtype='object')\n",
            "Skipping 'packet_rate' as required columns are missing.\n",
            "Skipping 'byte_rate' as required columns are missing.\n",
            "Best k: 1\n",
            "Final Accuracy: 61.13%\n",
            "Confusion Matrix:\n",
            "[[275  90  66  68   0]\n",
            " [ 82 243  91  82   0]\n",
            " [ 92  87 241  79   0]\n",
            " [ 76  69  87 267   0]\n",
            " [  0   0   0   0 498]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.55      0.54       499\n",
            "           1       0.50      0.49      0.49       498\n",
            "           2       0.50      0.48      0.49       499\n",
            "           3       0.54      0.54      0.54       499\n",
            "           4       1.00      1.00      1.00       498\n",
            "\n",
            "    accuracy                           0.61      2493\n",
            "   macro avg       0.61      0.61      0.61      2493\n",
            "weighted avg       0.61      0.61      0.61      2493\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Machine learning/new2/simulated_ddos_attack.csv\")\n",
        "\n",
        "# Check available columns\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "\n",
        "# Feature Engineering: Only add features that exist in the dataset\n",
        "if 'duration' in df.columns:\n",
        "    df['duration'] = df['duration'].replace(0, 1)  # Avoid division by zero\n",
        "\n",
        "if 'packet_count' in df.columns and 'duration' in df.columns:\n",
        "    df['packet_rate'] = df['packet_count'] / df['duration']\n",
        "else:\n",
        "    print(\"Skipping 'packet_rate' as required columns are missing.\")\n",
        "\n",
        "if 'byte_count' in df.columns and 'duration' in df.columns:\n",
        "    df['byte_rate'] = df['byte_count'] / df['duration']\n",
        "else:\n",
        "    print(\"Skipping 'byte_rate' as required columns are missing.\")\n",
        "\n",
        "# Drop high-cardinality categorical columns (IPs) if they exist\n",
        "for col in ['src_ip', 'dst_ip']:\n",
        "    if col in df.columns:\n",
        "        df.drop(columns=[col], inplace=True)\n",
        "\n",
        "# One-Hot Encode 'protocol' if it exists\n",
        "if 'protocol' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['protocol'])\n",
        "\n",
        "# Encode target variable if present\n",
        "if 'attack_type' in df.columns:\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['attack_type'] = label_encoder.fit_transform(df['attack_type'])\n",
        "else:\n",
        "    raise KeyError(\"Target column 'attack_type' is missing from the dataset.\")\n",
        "\n",
        "# Splitting features and target\n",
        "X = df.drop(columns=['attack_type'])\n",
        "y = df['attack_type']\n",
        "\n",
        "# Handling Class Imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Standardizing the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Finding the best k-value and distance metric\n",
        "best_k = 1\n",
        "best_accuracy = 0\n",
        "for k in range(1, 21):\n",
        "    knn = KNeighborsClassifier(n_neighbors=k, weights='distance', metric='minkowski')\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_k = k\n",
        "\n",
        "# Train final KNN model with best k\n",
        "knn = KNeighborsClassifier(n_neighbors=best_k, weights='distance', metric='minkowski')\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Compute confusion matrix and performance metrics\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Best k: {best_k}\")\n",
        "print(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Machine learning/new2/simulated_ddos_attack.csv\")\n",
        "\n",
        "# Check available columns\n",
        "print(\"Columns in dataset:\", df.columns)\n",
        "\n",
        "# Convert timestamp into useful time-based features\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df['hour'] = df['timestamp'].dt.hour\n",
        "df['minute'] = df['timestamp'].dt.minute\n",
        "df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "# Convert IPs into frequency counts (instead of direct encoding)\n",
        "df['src_ip_count'] = df.groupby('src_ip')['src_ip'].transform('count')\n",
        "df['dst_ip_count'] = df.groupby('dst_ip')['dst_ip'].transform('count')\n",
        "df.drop(columns=['src_ip', 'dst_ip'], inplace=True)\n",
        "\n",
        "# One-Hot Encoding for categorical columns (protocol & ports)\n",
        "df = pd.get_dummies(df, columns=['protocol', 'src_port', 'dst_port'])\n",
        "\n",
        "# Encode attack_type (target variable)\n",
        "label_encoder = LabelEncoder()\n",
        "df['attack_type'] = label_encoder.fit_transform(df['attack_type'])\n",
        "\n",
        "# Splitting features and target\n",
        "X = df.drop(columns=['attack_type'])\n",
        "y = df['attack_type']\n",
        "\n",
        "# Handling Class Imbalance using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf = RandomForestClassifier(n_estimators=200, random_state=42, max_depth=15, class_weight='balanced')\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Compute accuracy and performance metrics\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Final Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8mtVa5bTDAv",
        "outputId": "80490243-17b5-422e-aa65-a113d8771894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns in dataset: Index(['timestamp', 'src_ip', 'dst_ip', 'protocol', 'src_port', 'dst_port',\n",
            "       'length', 'attack_type'],\n",
            "      dtype='object')\n",
            "Final Accuracy: 42.08%\n",
            "Confusion Matrix:\n",
            "[[ 45 339   0 115   0]\n",
            " [ 28 367   0 103   0]\n",
            " [ 44 350   0 105   0]\n",
            " [ 30 330   0 139   0]\n",
            " [  0   0   0   0 498]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.31      0.09      0.14       499\n",
            "           1       0.26      0.74      0.39       498\n",
            "           2       0.00      0.00      0.00       499\n",
            "           3       0.30      0.28      0.29       499\n",
            "           4       1.00      1.00      1.00       498\n",
            "\n",
            "    accuracy                           0.42      2493\n",
            "   macro avg       0.37      0.42      0.36      2493\n",
            "weighted avg       0.37      0.42      0.36      2493\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Machine learning/new2/synthetic_high_accuracy_dataset.csv\")\n",
        "\n",
        "# Process 'timestamp' if it exists\n",
        "if 'timestamp' in df.columns:\n",
        "    df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "    df['hour'] = df['timestamp'].dt.hour\n",
        "    df['minute'] = df['timestamp'].dt.minute\n",
        "    df.drop(columns=['timestamp'], inplace=True)\n",
        "\n",
        "# Convert IPs into frequency counts\n",
        "if 'src_ip' in df.columns and 'dst_ip' in df.columns:\n",
        "    df['src_ip_count'] = df.groupby('src_ip')['src_ip'].transform('count')\n",
        "    df['dst_ip_count'] = df.groupby('dst_ip')['dst_ip'].transform('count')\n",
        "    df.drop(columns=['src_ip', 'dst_ip'], inplace=True)\n",
        "\n",
        "# One-hot encode 'protocol' if present\n",
        "if 'protocol' in df.columns:\n",
        "    df = pd.get_dummies(df, columns=['protocol'])\n",
        "\n",
        "# Port Feature Engineering: Mean encoding by attack type\n",
        "if 'src_port' in df.columns and 'dst_port' in df.columns and 'attack_type' in df.columns:\n",
        "    df['src_port_mean'] = df.groupby('attack_type')['src_port'].transform('mean')\n",
        "    df['dst_port_mean'] = df.groupby('attack_type')['dst_port'].transform('mean')\n",
        "    df.drop(columns=['src_port', 'dst_port'], inplace=True)\n",
        "\n",
        "# Encode attack_type (target variable)\n",
        "if 'attack_type' in df.columns:\n",
        "    label_encoder = LabelEncoder()\n",
        "    df['attack_type'] = label_encoder.fit_transform(df['attack_type'])\n",
        "else:\n",
        "    raise KeyError(\"❌ Error: 'attack_type' column is missing, cannot proceed with training.\")\n",
        "\n",
        "# Splitting features and target\n",
        "X = df.drop(columns=['attack_type'])\n",
        "y = df['attack_type']\n",
        "\n",
        "# Splitting into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Standardizing numerical features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train XGBoost Classifier with optimized parameters\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    n_estimators=150,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.05,\n",
        "    subsample=0.8,\n",
        "    colsample_bytree=0.8,\n",
        "    reg_lambda=1,\n",
        "    reg_alpha=0.5,\n",
        "    objective=\"multi:softmax\",\n",
        "    eval_metric=\"mlogloss\"\n",
        ")\n",
        "\n",
        "# Train XGBoost\n",
        "xgb_clf.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "\n",
        "# Predictions\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "\n",
        "# Compute accuracy and performance metrics\n",
        "final_accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "# Save model\n",
        "xgb_clf.save_model(\"/content/drive/MyDrive/Machine learning/new2/xgb_model.json\")\n",
        "\n",
        "print(f\"✅ Final Accuracy: {final_accuracy * 100:.2f}%\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"Classification Report:\")\n",
        "print(class_report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXCP1C6PTj64",
        "outputId": "8b91b590-580e-4ae9-c30d-462408330a7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final Accuracy: 98.10%\n",
            "Confusion Matrix:\n",
            "[[199   0   0   0   1]\n",
            " [  3 196   1   0   0]\n",
            " [  1   0 193   0   5]\n",
            " [  3   0   1 196   1]\n",
            " [  2   0   1   0 197]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       200\n",
            "           1       1.00      0.98      0.99       200\n",
            "           2       0.98      0.97      0.98       199\n",
            "           3       1.00      0.98      0.99       201\n",
            "           4       0.97      0.98      0.98       200\n",
            "\n",
            "    accuracy                           0.98      1000\n",
            "   macro avg       0.98      0.98      0.98      1000\n",
            "weighted avg       0.98      0.98      0.98      1000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}